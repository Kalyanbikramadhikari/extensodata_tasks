{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T03:56:43.950537Z",
     "start_time": "2024-05-22T03:56:43.768973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "layout1 = pd.read_csv('F:/Entity_Matching/pythonProject/data/ABC_layout_1.csv')\n",
    "layout2 = pd.read_csv('F:/Entity_Matching/pythonProject/data/PQR_layout_2.csv')\n",
    "layout3 = pd.read_csv('F:/Entity_Matching/pythonProject/data/layout_3_voters.csv')\n",
    "layout4 = pd.read_csv('F:/Entity_Matching/pythonProject/data/KLM_layout_4.csv')\n",
    "layout5 = pd.read_csv('F:/Entity_Matching/pythonProject/data/PQR_layout_2.csv')\n",
    "\n",
    "del layout1[\"Last Name\"]\n",
    "del layout2[\"Unnamed: 0\"]\n",
    "del layout4[\"Unnamed: 0\"]\n",
    "\n",
    "layout1 = layout1.rename(columns={\"First Name\": \"Name\", \"Father Name\": \"Father_Name\", \"Permanent_Adress\":\"Permanent_Address\"})\n",
    "layout2 = layout2.rename(columns = {\"Customer_ID\": \"Mobile Number\"})\n",
    "layout3 = layout3.rename(columns={\"votersName\": \"Name\", \"votersFatherName\": \"Father_Name\", \"votersMotherName\": \"Mother Name\", \" Gender\": \"Gender\", \"Permanent_Adress\":\"Permanent_Address\"})\n",
    "layout4 = layout4.rename(columns={\"Father Name\": \"Father_Name\"})\n",
    "\n",
    "layout1_ = layout1.copy()\n",
    "layout2_ = layout2.copy()\n",
    "layout3_ = layout3.copy()\n",
    "layout4_ = layout4.copy()\n",
    "layout5_ = layout5.copy()\n",
    "\n",
    "\n",
    "def sanitize(df):\n",
    "    return df.map(lambda x: x.replace(',', '').replace(' ', '').strip() if isinstance(x, str) else x)\n",
    "\n",
    "layout1_ = sanitize(layout1_)\n",
    "layout2_ = sanitize(layout2_)\n",
    "layout3_ = sanitize(layout3_)\n",
    "layout4_ = sanitize(layout4_)\n",
    "layout5_ = sanitize(layout5_)\n",
    "\n",
    "soup1 = ['Name', 'Date of Birth', 'Father_Name']\n",
    "soup2 = ['Name', 'Date of Birth', 'Father_Name']\n",
    "soup3 = ['Name', 'Date of Birth', 'Father_Name']\n",
    "soup4 = ['Name', 'Date of Birth', 'Father_Name']\n",
    "soup5 = ['Name', 'Date of Birth', 'Father_Name']\n",
    "\n",
    "def create_soup(df, df_, soup, soup_name):\n",
    "    df[soup_name] = df_[soup].apply(lambda x: ' '.join(x.values.astype(str)).lower(), axis=1)\n",
    "\n",
    "create_soup(layout1, layout1_, soup1, 'soup1')\n",
    "create_soup(layout2, layout2_, soup2, 'soup2')\n",
    "create_soup(layout3, layout3_, soup3, 'soup3')\n",
    "create_soup(layout4, layout4_, soup4, 'soup4')\n",
    "create_soup(layout5, layout5_, soup5, 'soup5')\n",
    "\n",
    "\n",
    "def column_remover(df):\n",
    "\n",
    "    columns = [\"Name\", \"Date of Birth\", \"Father_Name\", \"Temporary_Address\", \"Mobile Number\", \"Permanent_Address\",  \"Mother Name\"]\n",
    "    column_pairs = [(col, f\"{col}_x\", f\"{col}_y\") for col in columns]\n",
    "\n",
    "    for new_col, col_x, col_y in column_pairs:\n",
    "        if col_x in df.columns and col_y in df.columns:\n",
    "            df[new_col] = df[col_x].combine_first(df[col_y])\n",
    "            df.drop([col_x, col_y], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def combine_layouts(A, B, soup_A, soup_B, threshold=0):\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    combined_soup = pd.concat([A[soup_A], B[soup_B]], ignore_index=True)\n",
    "    tfidf.fit(combined_soup)\n",
    "    \n",
    "    tfidf_matrix_A = tfidf.transform(A[soup_A])\n",
    "    tfidf_matrix_B = tfidf.transform(B[soup_B])\n",
    "    \n",
    "    similarity = cosine_similarity(tfidf_matrix_A, tfidf_matrix_B)\n",
    "    similarity_df = pd.DataFrame(similarity, index=A.index, columns=B.index)\n",
    "\n",
    "    max_idx_row = similarity_df.idxmax(axis=1)\n",
    "    similarity_mask = similarity_df.max(axis=1) > threshold\n",
    "    \n",
    "    combined_df = pd.DataFrame({\n",
    "        soup_A: A[soup_A].values,\n",
    "        soup_B: [B.loc[idx, soup_B] if mask else None for idx, mask in zip(max_idx_row.values, similarity_mask)]\n",
    "    })\n",
    "    \n",
    "    result = pd.merge(pd.merge(A, combined_df, on=soup_A, how='left'), B, on=soup_B,  how='inner')\n",
    "    result.drop(columns = soup_B, inplace = True)\n",
    "    column_remover(result)\n",
    "    return result\n",
    "\n",
    "result_12 = combine_layouts(layout1, layout2, 'soup1', 'soup2')\n",
    "result_123 = combine_layouts(result_12, layout3, 'soup1', 'soup3')\n",
    "result_1234 = combine_layouts(result_123, layout4, 'soup1', 'soup4')\n",
    "final_result = combine_layouts(result_1234, layout5, 'soup1', 'soup5')"
   ],
   "id": "1b2ba179d66ff227",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d0fb3ed8665f72b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T03:56:46.932656Z",
     "start_time": "2024-05-22T03:56:46.885947Z"
    }
   },
   "cell_type": "code",
   "source": "final_result",
   "id": "7fd6e4a634dd256b",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T03:55:39.626616Z",
     "start_time": "2024-05-22T03:55:39.611353Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fbfb49f3bee65db0",
   "execution_count": 2,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
