{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:33:24.496178Z",
     "start_time": "2024-05-22T05:33:24.480592Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:33:24.670159Z",
     "start_time": "2024-05-22T05:33:24.654567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_df(filename, file_path='../data'):\n",
    "    full_path = os.path.join(file_path, f'{filename}.csv')\n",
    "    try:\n",
    "        df = pd.read_csv(full_path)\n",
    "        print(f\"File '{filename}.csv' loaded successfully from '{file_path}'.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{filename}.csv' was not found in the directory '{file_path}'.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: The file '{filename}.csv' is empty.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error: The file '{filename}.csv' could not be parsed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:33:24.837297Z",
     "start_time": "2024-05-22T05:33:24.790424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layout1 = load_df('ABC_layout_1')\n",
    "layout2 = load_df('PQR_layout_2')\n",
    "layout3 = load_df('layout_3_voters')\n",
    "layout4 = load_df('KLM_layout_4')\n",
    "layout5 = load_df('layout_5_license_dropped')\n",
    "\n",
    "layout1 = layout1.rename(columns={\"First Name\": \"Name\", \"Father Name\": \"Father_Name\", \"Permanent_Adress\":\"Permanent_Address\"})\n",
    "layout2 = layout2.rename(columns = {\"Customer_ID\": \"Mobile Number\"})\n",
    "layout3 = layout3.rename(columns={\"votersName\": \"Name\", \"votersFatherName\": \"Father_Name\", \"votersMotherName\": \"Mother Name\", \" Gender\": \"Gender\", \"Permanent_Adress\":\"Permanent_Address\"})\n",
    "layout4 = layout4.rename(columns={\"Father Name\": \"Father_Name\"})\n",
    "\n",
    "del layout1[\"Last Name\"]\n",
    "del layout2[\"Unnamed: 0\"]\n",
    "del layout4[\"Unnamed: 0\"]"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:33:25.053032Z",
     "start_time": "2024-05-22T05:33:25.036015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sanitize(df):\n",
    "    return df.map(lambda x: x.replace(',', '').replace(' ', '').strip() if isinstance(x, str) else '' if pd.isna(x) else x)"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:33:25.682426Z",
     "start_time": "2024-05-22T05:33:25.666799Z"
    }
   },
   "cell_type": "code",
   "source": "layouts = [layout1, layout2, layout3, layout4, layout5]",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:33:26.369310Z",
     "start_time": "2024-05-22T05:33:26.338039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layout_copies = []\n",
    "for layout in layouts:\n",
    "    try:\n",
    "        if layout is not None:\n",
    "            sanitized_layout = sanitize(layout.copy())\n",
    "            layout_copies.append(sanitized_layout)\n",
    "        else:\n",
    "            layout_copies.append(None)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while sanitizing a layout: {e}\")\n",
    "        layout_copies.append(None)"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:33:27.312650Z",
     "start_time": "2024-05-22T05:33:27.300334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(len(layout_copies)):\n",
    "    layout_copies[i] = sanitize(layout_copies[i])"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:33:31.196235Z",
     "start_time": "2024-05-22T05:33:31.171533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_soup(df, df_, soup, soup_name):\n",
    "    df[soup_name] = df_[soup].apply(lambda x: ' '.join(x.values.astype(str)).lower(), axis=1)\n",
    "\n",
    "soup = ['Name', 'Date of Birth', 'Father_Name']\n",
    "\n",
    "for i, j, k, in zip(layouts, layout_copies, range(len(layouts))):\n",
    "    create_soup(i, j, soup, f\"soup{k+1}\")"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:40:21.060146Z",
     "start_time": "2024-05-22T05:40:20.797127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combine(A, B, soup_A, soup_B, threshold=0.3):\n",
    "    # Initialize the TF-IDF Vectorizer\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    # Combine the textual data for fitting the TF-IDF model\n",
    "    combined_soup = pd.concat([A[soup_A], B[soup_B]], ignore_index=True)\n",
    "    tfidf.fit(combined_soup)\n",
    "    \n",
    "    # Transform the textual data into TF-IDF matrices\n",
    "    tfidf_matrix_A = tfidf.transform(A[soup_A])\n",
    "    tfidf_matrix_B = tfidf.transform(B[soup_B])\n",
    "    \n",
    "    # Compute cosine similarity between the two matrices\n",
    "    similarity = cosine_similarity(tfidf_matrix_A, tfidf_matrix_B)\n",
    "    similarity_df = pd.DataFrame(similarity, index=A.index, columns=B.index)\n",
    "    \n",
    "    # Determine the index of the most similar row in B for each row in A\n",
    "    max_idx_row = similarity_df.idxmax(axis=1)\n",
    "    similarity_mask = similarity_df.max(axis=1) >= threshold\n",
    "    \n",
    "    # Initialize the combined DataFrame with A, ensuring all columns from both DataFrames\n",
    "    combined_columns = list(set(A.columns) | set(B.columns))\n",
    "    combined_data = pd.DataFrame(columns=combined_columns)\n",
    "    \n",
    "    # Merge the similar rows \n",
    "    for idx_A in A.index:\n",
    "        if similarity_mask[idx_A]:\n",
    "            idx_B = max_idx_row[idx_A]\n",
    "            combined_row = A.loc[idx_A].combine_first(B.loc[idx_B])\n",
    "        else:\n",
    "            combined_row = A.loc[idx_A]\n",
    "        combined_data = pd.concat([combined_data, combined_row.to_frame().T], ignore_index=True)\n",
    "    \n",
    "    # Append non-similar rows from B to A\n",
    "    new_records = B.loc[~B.index.isin(max_idx_row[similarity_mask].values)]\n",
    "    result = pd.concat([combined_data, new_records], ignore_index=True)\n",
    "    result.drop(columns=soup_B, inplace=True)\n",
    "    return result\n",
    "\n",
    "result_12 = combine(layout1, layout2, 'soup1', 'soup2')\n",
    "result_123 = combine(result_12, layout3, 'soup1', 'soup3')\n",
    "result_1234 = combine(result_123, layout4, 'soup1', 'soup4')\n",
    "final_result = combine(result_1234, layout5, 'soup1', 'soup5')\n"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T05:40:22.034509Z",
     "start_time": "2024-05-22T05:40:22.003248Z"
    }
   },
   "source": "final_result",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
